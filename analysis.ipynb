{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data format:  timestamp, src, dest, length, src port, dst port\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "print('Loading data...')\n",
    "data = np.load('data_correct.npy')\n",
    "nsamples = data.shape[0] \n",
    "max_src = data[:,1].max()\n",
    "data = torch.tensor(data).float()\n",
    "print(\"Samples:\", nsamples,\"\\n\") \n",
    "\n",
    "# prepare timestamps\n",
    "print('Pre-processing timestamps...\\n')\n",
    "for i in range(int(max_src)):\n",
    "    timestamps = data[ data[:,1] == i, 0 ] \n",
    "    timestamps[1:] = timestamps[1:] - timestamps[:-1] \n",
    "    timestamps[0] = 0 \n",
    "    data[ data[:,1] == i, 0 ] = timestamps \n",
    "\n",
    "### shuffle the data\n",
    "print('Shuffle the bit...\\n')\n",
    "data = data[ torch.randperm(data.shape[0]) ]\n",
    " \n",
    "# split in training, validation and test set\n",
    "print('Creating dataset...')\n",
    "train = data[:int(nsamples*0.6)]\n",
    "validation = data[int(nsamples*0.6):int(nsamples*0.8)]\n",
    "test = data[int(nsamples*0.8):]\n",
    "\n",
    "\n",
    "print(\"Samples train:\", train.shape[0])\n",
    "print(\"Samples validation:\", validation.shape[0])\n",
    "print(\"Samples test:\", test.shape[0])\n",
    "print(\"Total samples:\", data.shape[0])\n",
    "\n",
    "print('\\ndone.')\n",
    "test.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network\n",
    "class Net(nn.Module): \n",
    "    def __init__(self): \n",
    "        super(Net,self).__init__() \n",
    "        self.loss_fn = nn.CrossEntropyLoss()  # LogSoftmax + ClassNLL Loss \n",
    "        \n",
    "        self.layers = nn.Sequential( \n",
    "            nn.Linear(5,30), #Input: \"timestamp\", mac source\",\"destination\",\"source port\",\"dest port\"\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(30,90), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(90,90) #Out: \"User\"         \n",
    "        )\n",
    "        \n",
    "    def forward(self,x): \n",
    "        return self.layers(x)\n",
    "    \n",
    "    def loss_function(self, net_out, target):\n",
    "        return self.loss_fn(net_out, target)\n",
    "    \n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "stop_at = train.shape[0] - 1\n",
    "stop_at = 100000\n",
    "nbatch = 64\n",
    "lear_rate = 1e-4\n",
    "n = 21 #epochs\n",
    "stamp = 100\n",
    "\n",
    "# network preparation\n",
    "print(\"Creating the model...\\n\")\n",
    "net = Net()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "net.to(device)\n",
    "optimizer = optim.Adam(params=net.parameters(), lr=lear_rate)\n",
    "print(\"Ready to go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "print(\"Start training...\")\n",
    "dateTimeObj_start_0 = datetime.now()\n",
    "print(dateTimeObj_start_0)\n",
    "\n",
    "accuracy_train = 0\n",
    "max_acc_0 = 0\n",
    "listLoss_a = []\n",
    "listAccuracy_val_a = []\n",
    "\n",
    "\n",
    "for epoch in range(n):  \n",
    "\n",
    "    dateTimeObj_start= datetime.now()    \n",
    "    net.train()\n",
    "    mean_loss = 0.\n",
    "    correct = 0    \n",
    "    for it,batch in enumerate(train.split(nbatch)): \n",
    "        if it*nbatch > stop_at: break\n",
    "        batch = batch.to(device) #move calculus to GPU\n",
    "        targets = batch[:,1].long()   \n",
    "        net_input = batch[:,(0,2,3,4,5)]  \n",
    "        optimizer.zero_grad()     \n",
    "\n",
    "        output = net(net_input)\n",
    "        loss = net.loss_function(output, targets)  # that loss hides the one-hot encoding\n",
    "        loss.backward()   # Back propagation\n",
    "        optimizer.step()  # Updating gradients\n",
    "        mean_loss += loss.item() #average of batch loss\n",
    "\n",
    "    dateTimeObj_end = datetime.now()\n",
    "\n",
    "    net.eval() #evaluation\n",
    "    with torch.no_grad(): #do not update the model\n",
    "        correct_eval = 0\n",
    "        for it_eval,batch_eval in enumerate(validation.split(nbatch)):  \n",
    "            if it_eval*nbatch > stop_at: break\n",
    "            targets_eval = batch_eval[:,1].long()\n",
    "            net_input_eval = batch_eval[:,(0,2,3,4,5)]\n",
    "            optimizer.zero_grad()\n",
    "            output_eval = net(net_input_eval)\n",
    "            _, predicted_eval = torch.max(output_eval.data, 1)\n",
    "            correct_eval += (predicted_eval == targets_eval).sum()\n",
    "\n",
    "    tot = it_eval*nbatch\n",
    "    accuracy_eval = 1.*correct_eval/tot\n",
    "\n",
    "    if epoch != 0:\n",
    "        listLoss_a.append(mean_loss/it)\n",
    "        listAccuracy_val_a.append(accuracy_eval)\n",
    "\n",
    "    if epoch%stamp == 0 or epoch == n-1:\n",
    "        print(f\"Epoch {epoch}, MeanLoss: {mean_loss/it} and Accuracy val: {100.*accuracy_eval}%\")\n",
    "\n",
    "#time taken\n",
    "dateTimeObj_end = datetime.now()\n",
    "print(\"Trained in: \", dateTimeObj_end-dateTimeObj_start_0)\n",
    "\n",
    "#best accuracy\n",
    "max_val_a = max(listAccuracy_val_a)\n",
    "for i,element in enumerate(listAccuracy_val_a):\n",
    "    if element == max_val_a:\n",
    "        break\n",
    "print(\"\\nBest value of validation is: \", max_val_a.item()*100,\"% at\", i, \"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphic\n",
    "listLoss_a = np.asarray(listLoss_a, dtype=np.float32)\n",
    "listAccuracy_val_a = np.asarray(listAccuracy_val_a, dtype=np.float32)\n",
    "\n",
    "epochs = range(n-1)\n",
    "\n",
    "df_train_a=pd.DataFrame({'Epochs': epochs, 'Loss': listLoss_a})\n",
    "df_acc_val_a=pd.DataFrame({'Epochs': epochs, 'Accuracy': listAccuracy_val_a*100})\n",
    "\n",
    "# plot\n",
    "plt.plot( 'Epochs', 'Loss', data = df_train_a, linestyle='-', marker='o', color = 'skyblue' )\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Value')\n",
    "plt.show()\n",
    "\n",
    "plt.plot( 'Epochs', 'Accuracy', data = df_acc_val_a, linestyle = '-', marker='o', color = 'black', label = \"Val\")\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Value')\n",
    "plt.legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "net.eval() #evaluation\n",
    "with torch.no_grad(): #non modificare la rete\n",
    "    correct = 0\n",
    "    for it,batch in enumerate(test.split(64)): \n",
    "        if it*64 > stop_at: break #limit to 100k samples\n",
    "            \n",
    "        batch = batch.to(device) \n",
    "        targets = batch[:,1].long()\n",
    "        net_input = batch[:,(0,2,3,4,5)]\n",
    "        \n",
    "        output = net(net_input) \n",
    "        _, predicted = output.max(dim=1) \n",
    "        correct += (predicted == targets).sum() \n",
    "\n",
    "        \n",
    "    print(f\"Accuracy test: {100. * correct / (it*64)} %\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
